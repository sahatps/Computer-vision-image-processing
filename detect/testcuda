# -*- coding: utf-8 -*-
import torch
import os
import numpy as np
import cv2
from super_gradients.training import models
from super_gradients.training.utils.visualization.pose_estimation import PoseVisualization

# Instantiate the smaller model
yolo_nas_pose = models.get("yolo_nas_pose_s", pretrained_weights="coco_pose")

# Process single image for skeleton display
def process_single_image(image, prediction):
    pose_data = prediction.prediction
    skeleton_image = PoseVisualization.draw_poses(
        image=image.copy(),  # Draw on a copy of the original image
        poses=pose_data.poses,
        boxes=pose_data.bboxes_xyxy,
        scores=pose_data.scores,
        is_crowd=None,
        edge_links=pose_data.edge_links,
        edge_colors=pose_data.edge_colors,
        keypoint_colors=pose_data.keypoint_colors,
        joint_thickness=2,
        box_thickness=2,
        keypoint_radius=5
    )
    return skeleton_image

# Main function to run the model on webcam input
def main():
    print("Starting webcam processing...")

    # Open webcam
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("Error: Could not open webcam.")
        return

    # Get webcam properties
    fps = cap.get(cv2.CAP_PROP_FPS)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter('skeleton_output.mp4', fourcc, fps, (width, height))

    frame_skip = 2  # Skip every other frame to speed up processing

    while True:
        for _ in range(frame_skip):
            ret, frame = cap.read()
            if not ret:
                break

        if not ret:
            break

        # Resize the frame to speed up processing
        small_frame = cv2.resize(frame, (320, 240))

        # Run prediction on the current frame with fuse_model=False
        result = yolo_nas_pose.predict(small_frame, conf=0.3, fuse_model=False)  # Lower confidence threshold

        # Process the prediction
        skeleton_frame = process_single_image(frame, result)

        # Write the frame with skeleton overlay to output video
        out.write(skeleton_frame)

        # Display the frame in real-time
        cv2.imshow('Skeleton Overlay', skeleton_frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    # Release resources
    cap.release()
    out.release()
    cv2.destroyAllWindows()
    print("Webcam processing completed. Output saved as 'skeleton_output.mp4'.")

if __name__ == "__main__":
    main()

