import cv2
import mediapipe as mp
import numpy as np
import torch

# Load YOLOv9 model
model = torch.hub.load('ultralytics/yolov5', 'yolov5s')  # Replace with actual YOLOv9 model

# Initialize MediaPipe Pose
mp_pose = mp.solutions.pose
pose = mp_pose.Pose(model_complexity=1, min_detection_confidence=0.1, min_tracking_confidence=0.1)
mp_drawing = mp.solutions.drawing_utils

# Function to perform YOLO detection
def detect_objects(frame):
    results = model(frame)
    return results.xyxy[0].numpy()

# Capture video
cap = cv2.VideoCapture("D:\multicam\RDJ.mp4")

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    # YOLO object detection
    detections = detect_objects(frame)

    for det in detections:
        x1, y1, x2, y2, conf, cls = det
        if cls == 0 and conf > 0.5:  # Class 0 is 'person' in COCO dataset
            # Draw rectangle around detected human
            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)
            
            # Extract the region of interest (ROI) for pose detection
            roi = frame[int(y1):int(y2), int(x1):int(x2)]
            image_rgb = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)

            # MediaPipe Pose detection within the ROI
            results = pose.process(image_rgb)

            if results.pose_landmarks:
                landmarks = np.array([[landmark.x * roi.shape[1] + x1, landmark.y * roi.shape[0] + y1, landmark.z] for landmark in results.pose_landmarks.landmark])

                # Draw the pose annotation on the original frame
                for i, landmark in enumerate(landmarks):
                    x = int(landmark[0])
                    y = int(landmark[1])
                    cv2.circle(frame, (x, y), 5, (0, 255, 0), -1)
                mp_drawing.draw_landmarks(
                    frame[int(y1):int(y2), int(x1):int(x2)],
                    results.pose_landmarks,
                    mp_pose.POSE_CONNECTIONS
                )

    # Display the annotated frame
    cv2.imshow('YOLOv9 + MediaPipe Pose', frame)

    if cv2.waitKey(5) & 0xFF == 27:
        break

cap.release()
cv2.destroyAllWindows()
